{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de predición de cancer de mama (Wisconsin uci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rafa/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-642e7957c1c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from random import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos desde el repositorio oficial\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data',\n",
    "header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vemos la estructura del dataframe\n",
    "# Columna 0 --> ID\n",
    "# Columna 1 --> Clase\n",
    "# Columnas 2.. -> Datos\n",
    "df[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el dataset en (Conjunto de datos, Etiquetas)\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el conjunto total en dos subconjuntos (Train 80% / Test 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_clf = DecisionTreeClassifier(criterion='entropy', max_depth=None, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un flujo de trabajo (pipeline):\n",
    "# Paso 1 -> Escalar los datos\n",
    "# Paso 2 -> Analisis de componentes principales (Reduce la dimensionalidad)\n",
    "# Paso 3 -> Construimos un modelo utilizando Regresión Logística\n",
    "\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', XGBClassifier())])\n",
    "\n",
    "# Ajustamos el modelo a los datos de entrenamiento\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "#Calculamos la precisión del modelo utilizando los datos de test\n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como cambia el accuracy al aumentar el ruido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_noise_level(N, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    change = lambda x: 'M' if x == 'B' else 'B'\n",
    "    def change_rand(N):\n",
    "        return lambda x: change(x) if random() < N/100 else x\n",
    "    \n",
    "    y_train = list(map(change_rand(N), y_train))\n",
    "\n",
    "    pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', XGBClassifier())])\n",
    "\n",
    "    # Ajustamos el modelo a los datos de entrenamiento\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "    #Calculamos la precisión del modelo utilizando los datos de test\n",
    "    return pipe_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_noise_level(0, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [accuracy_noise_level(N, X_train, y_train, X_test, y_test) for N in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(range(40), accuracies);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_noise_level_robust(N, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    change = lambda x: 'M' if x == 'B' else 'B'\n",
    "    def change_rand(N):\n",
    "        return lambda x: change(x) if random() < N/100 else x\n",
    "    \n",
    "    y_train = list(map(change_rand(N), y_train))\n",
    "\n",
    "    pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', XGBClassifier(gamma=5))])\n",
    "\n",
    "    # Ajustamos el modelo a los datos de entrenamiento\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "    #Calculamos la precisión del modelo utilizando los datos de test\n",
    "    return pipe_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_robust = [accuracy_noise_level_robust(N, X_train, y_train, X_test, y_test) for N in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(range(40), accuracies);\n",
    "ax.plot(range(40), accuracies_robust);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    grad = (y_true - y_pred)/((y_true - y_pred)**4 + 1)\n",
    "    hess = (1 - 3*(y_true - y_pred)**4)/((y_true - y_pred)**4 + 1)**2\n",
    "    return grad, hess\n",
    "    \n",
    "    \n",
    "def custom_loss(y_true, y_pred):\n",
    "    grad = 2*(y_true - y_pred)\n",
    "    hess = y_true * 0 + 2\n",
    "    return grad, hess\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_noise_level_custom_robust(N, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    change = lambda x: 'M' if x == 'B' else 'B'\n",
    "    def change_rand(N):\n",
    "        return lambda x: change(x) if random() < N/100 else x\n",
    "    \n",
    "    y_train = list(map(change_rand(N), y_train))\n",
    "\n",
    "    pipe_lr = Pipeline([('scl', StandardScaler()),\n",
    "                    ('clf', XGBClassifier(objective='multi:softmax'))])\n",
    "\n",
    "    # Ajustamos el modelo a los datos de entrenamiento\n",
    "    pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "    #Calculamos la precisión del modelo utilizando los datos de test\n",
    "    return pipe_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies_custom_robust = [accuracy_noise_level_custom_robust(N, X_train, y_train, X_test, y_test) for N in range(40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_loss(np.array([0,1,1,2]), np.array([0,2,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(range(40), accuracies);\n",
    "ax.plot(range(40), accuracies_robust)\n",
    "ax.plot(range(40), accuracies_custom_robust);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
